Below is a **single, copy-pasteable instruction set** you can drop into the root of the Replit repo as
`README_BUILD.md`.  It gives engineering *everything* they need to wire up the iterative, self-play review-board, React front-end, Perplexity retrieval, nine expert agents **plus** the new Champion ↔ Challenger loop.

---

# Clinical-Study Ideator & Validator – Replit-Agent Build Guide

*(May 2025 – v1.0)*

---

## 1 High-level architecture

```
React (Vite, TS)  ⇄  FastAPI + Celery (Python 3.11)
                             ↘
     Perplexity → Evidence → 9 Reviewer Agents (gpt-4.1 mini)
                              ↘
                 Champion ↔ Challenger loop (gpt-4.1 proposer)
```

*All OpenAI calls, Perplexity calls and secrets live server-side.*

---

## 2 Directory / file map

```
/replit-agent
│
├─ main.py                     # FastAPI routes, SSE streamer
├─ tasks.py                    # Celery worker fan-out
├─ search_perplexity.py        # wrapper -> evidence_bundle
├─ idea_generator.py           # seed ideas (GPT-4.1 full)
├─ proposer.py                 # champion→challenger (GPT-4.1 full)
├─ aggregator.py               # MCDA blend, ranking, Δ calc
├─ schema.py                   # Pydantic models
│
├─ prompt_bank/                # ONE .md per reviewer
│   ├─ CLIN.md  STAT.md  SAF.md  REG.md
│   ├─ HEOR.md OPS.md  PADV.md  ETH.md
│   └─ COMM.md
│
├─ strategic_goal_weights.yaml # 10 strategic goals × 6 MCDA axes
└─ requirements.txt
/web
└─ (React app – see §6)
```

---

## 3 Environment variables

```
OPENAI_API_KEY=...
PPLX_API_KEY=...
REDIS_URL=redis://default:pass@127.0.0.1:6379/0
```

---

## 4 Pipeline (Champion-Challenger Self-Play)

| Step                         | Component                                                          | Notes                      |
| ---------------------------- | ------------------------------------------------------------------ | -------------------------- |
| **0 Bootstrap**              | `idea_generator.py` → N seed ideas (default 5)                     | GPT-4.1, `temperature=1.0` |
| *Review*                     | 9 reviewer agents in parallel                                      | model: gpt-4.1 mini        |
| *Pick champions*             | `aggregator.py` – top-1 per lane                                   | stored in `champion_table` |
| **Loop r = 1…K (default 3)** |                                                                    |                            |
| → `proposer.py`              | For each champion, build challenger using champion JSON + feedback | GPT-4.1, `temperature=1.2` |
| → Review Board               | Score **both** champion & challenger                               |                            |
| → `aggregator.py`            | If challenger score > champion + ε (0.005) → replace               |                            |
| → Streamer                   | Send JSON payload to `/stream/{id}` (SSE)                          |                            |
| Stop                         | No challengers beat champs **or** rounds==K **or** token cap hit   |                            |

**Per-lane tokens / round ≈ 11 k → ≃ \$0.012.**
5 lanes × 3 rounds ≈ \$0.18 total at May-2025 prices.

---

## 5 API contract

### 5.1 POST `/new-concept`

```json
{
  "drug_name":"Drug X",
  "indication":"DLBCL 2L",
  "strategic_goals":[
    {"goal":"defend_market_share","weight":0.6},
    {"goal":"biomarker_validation","weight":0.4}
  ],
  "geography":["DE","FR","IT","ES","UK"],
  "study_phase_pref":"III",
  "max_rounds":3,           // optional
  "lanes":5                 // optional (seed ideas)
}
```

Returns `tournament_id`.

### 5.2 GET `/stream/{id}`  (SSE)

Payload (one per round):

```json
{
  "round":2,
  "lanes":[
    {
      "lane_id":0,
      "champion":{ "idea_id":"A_v2","score":0.81 },
      "challenger":{ "idea_id":"A_v3","score":0.79 },
      "delta":+0.03           // champion score change vs prev round
    }, ...
  ],
  "timestamp":"2025-05-15T10:22:17Z"
}
```

### 5.3 GET `/feedback/{idea_id}/{agent_id}`

Returns strengths / weaknesses array for accordion cards.

---

## 6 React front-end checklist

1. **EventSource** to `/stream/{id}` → push rounds into Zustand/Context.
2. **Leaderboard (`<RoundTable />`)**

   ```tsx
   <DataTable rows={lanes}>
      <Column header="Lane" value="lane_id"/>
      <Column header="Champion" value={r=>r.champion.idea_id}/>
      <Column header="Score" value={r=>pct(r.champion.score)}/>
      <Column header="Δ" value={r=>signedPct(r.delta)} style={colorDelta}/>
   </DataTable>
   ```
3. **`<AgentAccordion />`** opens per idea → maps 9 `<AgentCard />` components.
4. Badge:

   ```tsx
   {idea.is_champion && <Chip color="emerald">Champion</Chip>}
   {!idea.is_champion && <Chip color="amber">Challenger</Chip>}
   ```

---

## 7 Reviewer prompt template (example: `COMM.md`)

```md
System: You are COMM, a commercial-strategy analyst.
Task: Score the incremental commercial value of the study below.

Return JSON **only**:
{
  "agent_id":"COMM",
  "score":0-1,
  "peak_sales_delta_eur":int,
  "defence_value_eur":int,
  "roi_years":float,
  "strengths":[],
  "weaknesses":[]
}
```

(Add equivalent templates for CLIN, STAT, SAF, REG, HEOR, OPS, PADV, ETH.)

---

## 8 MCDA axes & weight blend

Axes: `unmet_need, diff_vs_comp, LOE_potential, econ_impact, feasibility, safety`.
Reviewer-to-axis mapping lives in `strategic_goal_weights.yaml`.
Blend per strategic\_goal weights → vector `W_blend`, then:

```
OverallScore = Σ  axis  W_blend[axis] × reviewer_axis_score
```

---

## 9 Token / cost guards

```yaml
TOKEN_BUDGET:
  per_round: 60000        # hard abort if exceeded
  total:    120000
```

---

## 10 Acceptance criteria

1. **5 lanes × 3 rounds** run under **\$0.20**.
2. Leaderboard & Δ column stream live; champion badge updates.
3. Feedback accordion shows nine reviewer cards per idea.
4. Final champions downloadable as PDF / PPTX report.

---

### Done

Hand this file to the Replit devs—**all roles, prompts, routes, data shapes, and stop rules are specified.**  They can code-complete without further clarification.
